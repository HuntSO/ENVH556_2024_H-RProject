---
title: 'Week 3 Lab:  Regression for Association'
author: "Instructors for ENVH 556 Autumn 2024"
format:
  html:
    df_print: "paged"
    fig_caption: yes
    toc: true
    toc_depth: 3
    number_sections: true
    self-contained: true #save images etc. in this file (vs folders)
execute:
  echo: true
  cache: false
  echo.comments: false
  message: false
  warning: false
editor_options: 
  chunk_output_type: console
---

This document was rendered on `r format(Sys.time(), '%B %d, %Y')`.

```{r setup, include=FALSE}
#-----setup-----

# clear work space of all objects and unload all extra (non-base) packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
    res <- suppressWarnings(
        lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
               detach, character.only=TRUE, unload=TRUE, force=TRUE))
   
}

```

```{r load.libraries.pacman, echo=FALSE, include=FALSE, eval=TRUE}
#-----load libraries pacman-----

# Load pacman into memory, installing as needed
my_repo <- 'http://cran.r-project.org'
if (!require("pacman")) {install.packages("pacman", repos = my_repo)}

# Load the other packages, installing as needed.
pacman::p_load(knitr, kableExtra, tidyverse, egg, multcomp, modelr,
               broom # tidy() # optional
               )

```

```{r directory.organization.read.data, echo=FALSE, warning=FALSE}
#-----directory organization and read data-----

# specify data path
data_path <- file.path("Datasets")

# specify the file name and path
file_name <- "allseasonsR.rds"
file_path <- file.path(data_path, file_name)

# Download the file if it is not already present
if (!file.exists(file_path)) {
    url <- paste("https://faculty.washington.edu/sheppard/envh556/Datasets", 
                 file_name, sep = '/')
    download.file(url = url, destfile = file_path)
}

# Output a warning message if the file cannot be found
if (file.exists(file_path)) {
    snapshot<-readRDS(file_path)
} else warning(paste("Can't find", file_name, "!"))

# remove temporary variables
rm(url, file_name, file_path, data_path)

```

# Purpose

The purpose of this lab is to get practice using and reporting regression models with a focus on regression for association and some beginning work on regression for prediction. We will use the snapshot data for this lab.


# The Data

These snapshot data are described in the [Mercer et al, 2011](https://doi.org/10.1016/j.atmosenv.2011.05.043).  

* air pollution measurements were collected at increasing distances from roadways to capture concentration gradients     
* 100 locations in LA  
* 6 measurements per location at: $+-$ 50, 100, 350 m  
* during summer, fall, winter 

Variables we'll look at:      
* ID – location ID, integer values between 1 & 152    
* nox – oxides of nitrogen (NOx) in ppb    
* log-transformed NOx: ln_nox  
* season – season as an integer where 0=summer, 1=fall, 2=winter     
* seasonfac – season transformed to a factor variable for summer, fall, winter    

# Getting Started

This section gives some basic R commands for regression for association and the first steps for evaluating predictions.  

* Summarizing *ln_nox* by season  


```{r summarize.ln_nox}
#-----summarize ln_nox-----

# frequencies only
summary(snapshot$seasonfac)

# descriptive statistics
## we'll focus on the values shown on the boxplots in the native scale. There are situations where you may instead decide to report log units (e.g., to describe a plot only on log units). 

snapshot_summary <- snapshot %>%     
    group_by(seasonfac) %>%
    summarise(N = n(),
              # option to look at this if you wanted to summarize values on the log scale (in the figure)
              #Mean_log_scale = mean(ln_nox),
              #SD_log_scale = sd(ln_nox),
              
              Min = min(exp(ln_nox)),
              Q25 = quantile(exp(ln_nox), 0.25),
              Median = median(exp(ln_nox)),
              Q75 = quantile(exp(ln_nox), 0.75),
              Max = max(exp(ln_nox)),
              
              Mean = mean(exp(ln_nox)),
              SD = sd(exp(ln_nox)),
              
              GM = exp(mean(ln_nox)), 
              GSD = exp(sd(ln_nox)), 
              .groups = "drop")

# kable table
kable(snapshot_summary, 
      caption = "Distribution of NOx concentrations (ppb) by season.",
      digits=2) %>%
  kable_styling()
  

# compare central tendency measures
snapshot_summary %>%
  dplyr::select(seasonfac, Median, Mean, GM) %>%
  kable(.,
      caption = "Distribution of NOx concentrations (ppb) by season.",
      digits=0) %>%
  kable_styling()


```

Compare the mean, median, and GMs for each seaason. Are they very different? What might this tell you about the distribution of NOx? 


* Commands for season-specific boxplots:

```{r season-specific boxplots}
#-----season-specific boxplots-----
# consider updating the 2nd-axis labels. What else might you want to communicate? 
ggplot(snapshot, aes(x = seasonfac, y = ln_nox, fill = seasonfac)) +
    geom_boxplot() +
    labs(x = "Season", 
         y = "ln(NOx) (ln(ppb))", 
         color = "Season", 
         fill = "Season") +
   scale_y_continuous(
        sec.axis = sec_axis(~exp(.), name = "NOx (ppb)")  # Right y-axis with exponentiated values
    ) +
    theme_article() 

```

* Commands for regression: 

```{r regression for association}
#-----regression for association-----

# Common model (Table 4), season-specific LUR

# specify regression model
# predictors: distance to A1, A1 roads in 50m buffer, A2-3 roads in 400m buffer, pop in 5km buffer, distance to coast, intense land use in 3k km2, distance to commercial area
frml <- as.formula(ln_nox ~ D2A1 + A1_50 + A23_400 + Pop_5000 + D2C + Int_3000 + D2Comm)

# note: as.formula() works with strings as well!

# summarize the fit of each model
summary(lm_summer <- lm(frml, data = snapshot, subset = seasonfac == "1Summer"))
summary(lm_fall <- lm(frml, data = snapshot, subset = seasonfac == "2Fall"))
summary(lm_winter <- lm(frml, data = snapshot, subset = seasonfac == "3Winter"))

```

Let's look at some model output from the summer fit. 

```{r}
# coefficient (point) estimates
coef(lm_summer)

# this also works: 
# lm_summer$coefficients

# 95% confidence interval for coefficients
confint(lm_summer)

# number of observations used to fit the model
nobs(lm_summer)

# generates a tibble you can manipulate easier. 
## includes coefficients, SE, p-val 
lm_summer %>%
  broom::tidy()

```


* Making predictions:

This gives season-specific predictions in the dataset with all seasons.

```{r predictions.with.dplyr}
#-----predictions with dplyr-----

# this adds model-specific predictions. 
# Note that we are using a season-specific model to predict at all times 
# however, we don't get the prediction intervals or SEs this way
snap2 <- snapshot %>% 
    # summer
    add_residuals(lm_summer,"resids_sum") %>%
    add_predictions(lm_summer,"preds_sum") %>%
    
    # fall
    add_residuals(lm_fall,"resids_fall") %>%
    add_predictions(lm_fall,"preds_fall") %>%
    
    # winter
    add_residuals(lm_winter,"resids_win") %>%
    add_predictions(lm_winter,"preds_win")

# inspect predictions and residuals for one location
snap2 %>% 
  dplyr::select(ID, SeasonID = seasonfac, ln_nox, 
                preds_sum, preds_fall, preds_win, 
                #resids_sum, resids_fall, resids_win
                ) %>% 
  mutate_if(is.double, round, 2) %>%
  # example location
  filter(ID==first(ID))

```

Now we add prediction intervals:

```{r in-sample prediction intervals}
#-----in-sample prediction intervals-----

# first get the prediction interval for each season and bind it to the
# season-specific subset of the full dataset
# NOTE:  We are assuming the two datasets are in the same order when we cbind!
# It is good practice to check and not assume this is correct.
# R gives a warning about the interpretation of these prediction intervals when
# the data to generate the model are the same ones to do prediction.  This
# warning does not appear when the predictions are out of sample (see next
# chunk).
summer <- cbind(snapshot[snapshot$seasonfac=="1Summer",],predict(lm_summer,interval="prediction"))
fall <- cbind(snapshot[snapshot$seasonfac=="2Fall",],predict(lm_fall,interval="prediction"))
winter <- cbind(snapshot[snapshot$seasonfac=="3Winter",],predict(lm_winter,interval="prediction"))

# then combine the dataset into one big tibble
allseas_in <- rbind(summer, fall, winter) %>% as_tibble()

# rename the predictions to clarify that these are IN-SAMPLE predictions
allseas_in <- rename(allseas_in, pred_in = fit, lwr_in = lwr, upr_in = upr)

# let's look at an example location
allseas_in %>%
  filter(ID==first(ID)) %>%
  dplyr::select(ID, season, seasonfac, ln_nox, pred_in, lwr_in, upr_in)

```

```{r out-of-sample predictions}
#-----out-of-sample predictions-----

# This example produces out-of-sample season-specific prediction intervals using
# the previous season to predict the next one.  (Note you should think carefully
# from a scientific perspective about how to approach out-of-sample predictions
# like these.)

# get the prediction interval for each season 
fall_preds_from_summer <- 
  predict(lm_summer, snapshot[snapshot$seasonfac == "2Fall",], interval = "prediction")

winter_preds_from_fall <- 
  predict(lm_fall, snapshot[snapshot$seasonfac == "3Winter",], interval = "prediction")

summer_preds_from_winter <- 
  predict(lm_winter, snapshot[snapshot$seasonfac == "1Summer",], interval = "prediction")

# then combine the dataset into one big tibble and rename variables
allseas_out <- rbind(summer_preds_from_winter, 
                     fall_preds_from_summer,
                     winter_preds_from_fall) %>% 
  as_tibble() %>% 
  rename(pred_out = fit, lwr_out = lwr, upr_out = upr)

# Bind "out" predictions to the previous dataset with "in" sample predictions
# NOTE:  We assume the datasets are in the same order!
allseas_both <- cbind(allseas_in, allseas_out)

```

Now evaluate the quality of the predictions.  This is based on correlation between the prediction and the outcome.  It is the R^2^ for the best fit line of the relationship between the predictions and the data (*ln_nox* here).  It does not account for the systematic bias in the predictions.  Next week we will learn how to compute R^2^ about the 1:1 line which also addresses the systematic bias of the predictions.

```{r prediction assessment}
#-----prediction assessment-----

# summer in-sample
paste("summer in-sample R2:  ", 
      with(subset(allseas_both, seasonfac == "1Summer"), round(cor(ln_nox, pred_in)^2, 3))) 

# summer out-of-sample (from winter model)
paste("summer out-of-sample R2 (from winter model):  ", 
      with(subset(allseas_both, seasonfac == "1Summer"), round(cor(ln_nox, pred_out)^2,3)))

```

Let's look at what we mean by R^2^ about the best fit line by plotting the data we correlated above and incorporating the best fit lines.

Note that we use `pivot_longer()` to generate a multi-faceted plot. If you only want to display one season, a simpler approach could be used without the need for reshaping the data.

* x-axis shows observed ln NOx    
* y-axis shows predicted ln NOx   
* Columns show the season data we are looking at (e.g., summer)   
* top row shows results from in-sample predictions 
* bottom row shows results from out-of-sample predictions (e.g., winter model used to predict during the summer) 

For example, the top left panel shows observed (x-axis) vs predicted (y-axis) summer concentrations when using the summer model to predict summer (in-sample) concentrations

```{r summer.in.and.out.sample, message=FALSE}
#----- in and out of sample-----

# plot the predictions vs. data for models, both in-sample and out of sample

# get the range of the data to use as limits in the plots
r <- allseas_both %>% 
  dplyr::select(pred_in, pred_out, ln_nox) %>% 
  range()

allseas_both %>%
  dplyr::select(ID, seasonfac, ln_nox, pred_in, pred_out) %>%
  # make long format for plotting
  pivot_longer(cols = c(pred_in, pred_out), names_to = "prediction_type", values_to = "value") %>%
  mutate(prediction_type = ifelse(prediction_type=="pred_in", "In-Sample",
                                  ifelse(prediction_type=="pred_out", "Out-of-Sample", NA))) %>%
   
  ggplot(aes(x = ln_nox, y = value, col=seasonfac)) +
  facet_grid(rows = vars(prediction_type), cols = vars(seasonfac)) +
  geom_point(alpha=0.4) +
    lims(x = c(r[1], r[2]), y = c(r[1], r[2]) ) +
    coord_fixed() +
    geom_abline(intercept = 0, slope = 1) +
    geom_smooth(method = "lm", se = FALSE) +
    labs(title = "In-sample and out-of-sample predictions", 
         y = "predicted ln(NOx) (ln(ppb))",
         x = "Observed ln(NOx) (ln(ppb))"
         ) + 
    theme_bw()

```

Why do out-of-sample predictions typically look worse? 


# Practice Session
This section covers basic practice to be completed during the lab.   

Perform the following tasks: 

1.	Set up/decide your project for this lab.  

2.	Read in the snapshot data and get some basic understanding of its structure.   

3.	Summarize *ln_nox*, the outcome variable of interest     
    a.	Summarize by season    
    b.	Can you produce a nice summary figure of the data?  Should they be on the log or the native scale?  Is it useful to put multiple pollutants (NO, NOx, NO2) in the same figure?  

4.	Replicate the season-specific models in Table 4 of [Mercer et al, 2011](https://doi.org/10.1016/j.atmosenv.2011.05.043).  (Only focus on the LUR model results.  Also we’ll talk about cross-validation in an upcoming week so recognize your in-sample R^2^ should be a bit bigger and your RMSE should be a bit smaller than the values in the paper.)  
    a.	Compare your coefficient estimates and standard errors, as well as LUR R^2^ and sample size.  (Note:  You may need to consider rounding in your comparison.)  
    b.	Are all your terms parameterized the same as they are in the paper?  

5.	Use the fall model to predict ln_nox in summer and vice versa.    
    a.	Assess the quality of the predictions.  (Using the information from the lecture on regression for association, compute the R^2^, and plot the predictions and the prediction intervals.)  
    b.	What have you learned?  Does this flipping of models across seasons make sense scientifically?  Why or why not?  


# Homework Exercises  

1.	Describe the NOx variable.  Develop one figure and one table to best capture your data and then write a paragraph describing what these show.  (Doing both is for practice.  In a peer-reviewed paper you will ordinarily only show one of these.)  In the table, you may find it helpful to also include information on the covariates you use in your model(s) in this lab.    

2.	Using the terminology given in lecture, briefly discuss the fall season common LUR model results.  Include in your discussion an interpretation for at least two terms in the fall season model.   

3.	Focusing on the common models in Table 4 of [Mercer et al, 2011](https://doi.org/10.1016/j.atmosenv.2011.05.043), think about how to use the data from all seasons at once to get season-specific parameter estimates. What terms do you need to incorporate the interactions?   
    a.  How is your interaction model different from fitting three separate season-specific models?

4.	Make table(s) and/or figure(s) summarizing your results for practice exercise 5.  Discuss.  

# Appendix

```{r session.info}
#-----session information----

# print R session information
sessionInfo()

```

```{r code.appendix, ref.label = knitr::all_labels(), echo = TRUE, eval = FALSE, , include=TRUE}
#-----code appendix----
```

```{r functions, eval = TRUE}
#-----functions----

# Show the names of all functions defined in the .Rmd
# (e.g. loaded in the environment)
lsf.str()

# Show the definitions of all functions loaded into the current environment  
lsf.str() %>% set_names() %>% map(get, .GlobalEnv)

```


